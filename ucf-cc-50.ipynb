{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":497705,"sourceType":"datasetVersion","datasetId":233465}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models, transforms\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport numpy as np\nfrom PIL import Image\nimport h5py\nfrom sklearn.model_selection import KFold\nimport torch.nn.functional as F\nimport random\ndef set_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False \n\nset_seed(38)\nclass CrowdDataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        self.data_dir = data_dir\n        self.image_filenames = [f for f in os.listdir(data_dir) if f.endswith('.jpg')]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_filenames)\n\n    def __getitem__(self, idx):\n        img_filename = self.image_filenames[idx]\n        density_filename = img_filename.replace('.jpg', '.h5')\n        img_path = os.path.join(self.data_dir, img_filename)\n        density_path = os.path.join(self.data_dir, density_filename)\n        image = Image.open(img_path).convert('RGB')\n\n        with h5py.File(density_path, 'r') as hf:\n            density_map = np.array(hf['density'])\n\n        if self.transform:\n            image = self.transform(image)\n\n        density_map = torch.from_numpy(density_map).unsqueeze(0).float()  \n\n        return image, density_map\n\nclass DConvNet_v1(nn.Module):\n    def __init__(self, pretrained=True, num_regressors=3):\n        super(DConvNet_v1, self).__init__()\n\n        vgg16 = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n\n        self.features = nn.Sequential(*list(vgg16.features.children())[:23])\n\n        self.features.add_module('pool4', nn.MaxPool2d(kernel_size=2, stride=1, padding=0))\n\n        self.features.add_module('dilated_conv5_1', nn.Conv2d(512, 512, kernel_size=3, padding=2, dilation=2))\n        self.features.add_module('relu5_1', nn.ReLU(inplace=True))\n        self.features.add_module('dilated_conv5_2', nn.Conv2d(512, 512, kernel_size=3, padding=2, dilation=2))\n        self.features.add_module('relu5_2', nn.ReLU(inplace=True))\n        self.features.add_module('dilated_conv5_3', nn.Conv2d(512, 512, kernel_size=3, padding=2, dilation=2))\n        self.features.add_module('relu5_3', nn.ReLU(inplace=True))\n\n        self.regressors = nn.ModuleList([\n            nn.Sequential(\n                nn.Conv2d(512, 64, kernel_size=1, groups=64),  \n                nn.ReLU(inplace=True),\n                nn.Dropout(0.3),  \n                nn.Conv2d(64, 1, kernel_size=1)\n            ) for _ in range(num_regressors)\n        ])\n        self.regressors.apply(self.init_weights)\n\n    def forward(self, x):\n        x = self.features(x)\n        outputs = [regressor(x) for regressor in self.regressors]\n        return outputs\n\n    def init_weights(self, m):\n        if isinstance(m, nn.Conv2d):\n            torch.nn.init.xavier_uniform_(m.weight)\n            if m.bias is not None:\n                m.bias.data.fill_(0.01)\n\ndef negative_correlation_loss(outputs, target, lambda_param=0.001):\n    mse_loss = nn.MSELoss()\n    target = target.to(outputs[0].device)\n    total_mse = sum([mse_loss(F.interpolate(output, size=target.shape[2:], mode='bilinear', align_corners=False), target) for output in outputs]) / len(outputs)\n\n    correlations = []\n    for i in range(len(outputs)):\n        for j in range(i + 1, len(outputs)):\n            o_i = outputs[i].view(-1)\n            o_j = outputs[j].view(-1)\n            corr = torch.corrcoef(torch.stack([o_i, o_j]))[0, 1]\n            correlations.append(corr)\n\n    correlation_penalty = -sum(correlations) / (len(correlations) + 1e-8) if correlations else 0\n    return total_mse + lambda_param * correlation_penalty\n\ndef get_optimizer(model):\n    return optim.SGD([\n        {'params': model.features.parameters(), 'lr': 1e-5},  \n        {'params': model.regressors.parameters(), 'lr': 1e-3}\n    ], momentum=0.9, weight_decay=1e-3)\n\ndef get_scheduler(optimizer):\n    return optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n\ndef custom_collate(batch):\n    max_height = max([item[0].shape[1] for item in batch])\n    max_width = max([item[0].shape[2] for item in batch])\n\n    resized_images = []\n    resized_density_maps = []\n    for image, density_map in batch:\n        image = F.interpolate(image.unsqueeze(0), size=(max_height, max_width), mode='bilinear', align_corners=False)\n        image = image.squeeze(0)\n\n        density_map = F.interpolate(density_map.unsqueeze(0), size=(max_height, max_width), mode='bilinear', align_corners=False)\n        density_map = density_map.squeeze(0)\n\n        resized_images.append(image)\n        resized_density_maps.append(density_map)\n\n    return torch.stack(resized_images), torch.stack(resized_density_maps)\n\ndef train_model(model, train_dataloader, test_dataloader, num_epochs=40, lambda_param=0.001, save_path='model_checkpoint.pth'):\n    model = model.to(device)\n    optimizer = get_optimizer(model)\n    scheduler = get_scheduler(optimizer)\n    best_mae = float('inf')\n    early_stop_patience = 5\n    no_improve_epochs = 0\n\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        model.train()\n        for images, density_maps in train_dataloader:\n            images = images.to(device)\n            density_maps = density_maps.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = negative_correlation_loss(outputs, density_maps, lambda_param)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_dataloader)}\")\n\n        model.eval()\n        mae, rmse = evaluate_model(model, test_dataloader)\n\n        if mae < best_mae:\n            best_mae = mae\n            no_improve_epochs = 0\n            # torch.save(model.state_dict(), f'{save_path}_epoch_{epoch+1}.pth')\n            # print(f\"Model saved as {save_path}_epoch_{epoch+1}.pth\")\n        else:\n            no_improve_epochs += 1\n\n        if no_improve_epochs >= early_stop_patience:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n\n        scheduler.step()\n\ndef evaluate_model(model, dataloader):\n    model.eval()\n    mae, rmse = 0.0, 0.0\n    with torch.no_grad():\n        for images, density_maps in dataloader:\n            images = images.to(device)\n            density_maps = density_maps.to(device)\n\n            outputs = model(images)\n            avg_output = sum(outputs) / len(outputs)\n\n            mae += torch.abs(avg_output.sum() - density_maps.sum()).item()\n            rmse += ((avg_output.sum() - density_maps.sum()) ** 2).item()\n\n    mae /= len(dataloader)\n    rmse = (rmse / len(dataloader)) ** 0.5\n    print(f\"Validation MAE: {mae}, Validation RMSE: {rmse}\")\n    return mae, rmse\n\ndef cross_validate_model(model, dataset, num_epochs=40, k_folds=5, lambda_param=0.001):\n    kfold = KFold(n_splits=k_folds, shuffle=True)\n    fold_results = {'mae': [], 'rmse': []}\n    \n    for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n        print(f'FOLD {fold + 1}/{k_folds}')\n        print('--------------------------------')\n\n        train_subset = Subset(dataset, train_ids)\n        test_subset = Subset(dataset, test_ids)\n\n        train_dataloader = DataLoader(train_subset, batch_size=4, shuffle=True, num_workers=4, collate_fn=custom_collate)\n        test_dataloader = DataLoader(test_subset, batch_size=4, shuffle=False, num_workers=4, collate_fn=custom_collate)\n\n        model_fold = DConvNet_v1(pretrained=True)\n        model_fold = model_fold.to(device)\n\n        train_model(model_fold, train_dataloader, test_dataloader, num_epochs, lambda_param, save_path=f'model_checkpoint_fold_{fold + 1}.pth')\n\n        mae, rmse = evaluate_model(model_fold, test_dataloader)\n        fold_results['mae'].append(mae)\n        fold_results['rmse'].append(rmse)\n\n        print(f'Fold {fold + 1} Results - MAE: {mae}, RMSE: {rmse}')\n        print('--------------------------------')\n\n    avg_mae = np.mean(fold_results['mae'])\n    avg_rmse = np.mean(fold_results['rmse'])\n\n    print(f'\\nCross-validation Results:')\n    print(f'Average MAE: {avg_mae}')\n    print(f'Average RMSE: {avg_rmse}')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Path to the folder containing both images and density maps\ndata_dir = '/kaggle/input/ucf-cc-50-with-people-density-map/UCF_CC_50'\n\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n])\n\ndataset = CrowdDataset(data_dir, transform=data_transforms)\n\nmodel = DConvNet_v1(pretrained=True)\n\ncross_validate_model(model, dataset, num_epochs=40, k_folds=5, lambda_param=0.001)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-10-22T15:58:40.272620Z","iopub.execute_input":"2024-10-22T15:58:40.273071Z","iopub.status.idle":"2024-10-22T16:01:24.483444Z","shell.execute_reply.started":"2024-10-22T15:58:40.273025Z","shell.execute_reply":"2024-10-22T16:01:24.482302Z"}},"outputs":[{"name":"stdout","text":"FOLD 1/5\n--------------------------------\nEpoch 1/40, Loss: 0.003496061731129885\nValidation MAE: 447.00665283203125, Validation RMSE: 465.6704899479173\nEpoch 2/40, Loss: 0.003222417028155178\nValidation MAE: 437.75767008463544, Validation RMSE: 455.806433925996\nEpoch 3/40, Loss: 0.00293611359084025\nValidation MAE: 425.164311726888, Validation RMSE: 442.67174456644506\nEpoch 4/40, Loss: 0.0027060977881774306\nValidation MAE: 420.38197326660156, Validation RMSE: 438.0140031175754\nEpoch 5/40, Loss: 0.002379937598016113\nValidation MAE: 409.29469299316406, Validation RMSE: 426.07588238726134\nEpoch 6/40, Loss: 0.00233909641392529\nValidation MAE: 411.86363728841144, Validation RMSE: 428.53469600148287\nEpoch 7/40, Loss: 0.0022839986020699145\nValidation MAE: 405.69276936848956, Validation RMSE: 422.2940295526724\nEpoch 8/40, Loss: 0.0022706508636474608\nValidation MAE: 403.6186777750651, Validation RMSE: 420.2694014458662\nEpoch 9/40, Loss: 0.0022955797030590475\nValidation MAE: 398.4171091715495, Validation RMSE: 415.3168986473863\nEpoch 10/40, Loss: 0.002239678520709276\nValidation MAE: 399.6377817789714, Validation RMSE: 416.21499477433537\nEpoch 11/40, Loss: 0.0021712333080358805\nValidation MAE: 397.34490966796875, Validation RMSE: 413.87055456688387\nEpoch 12/40, Loss: 0.0022798161837272344\nValidation MAE: 401.666753133138, Validation RMSE: 418.1024408463393\nEpoch 13/40, Loss: 0.002213730092626065\nValidation MAE: 395.71484375, Validation RMSE: 412.2478806545482\nEpoch 14/40, Loss: 0.002055289864074439\nValidation MAE: 396.5312042236328, Validation RMSE: 412.4326570660759\nEpoch 15/40, Loss: 0.00214370732428506\nValidation MAE: 397.66883341471356, Validation RMSE: 414.54764188912395\nEpoch 16/40, Loss: 0.0021802755538374184\nValidation MAE: 392.10276794433594, Validation RMSE: 408.401896879777\nEpoch 17/40, Loss: 0.002077917626593262\nValidation MAE: 395.0979970296224, Validation RMSE: 411.670858615634\nEpoch 18/40, Loss: 0.0020785882021300494\nValidation MAE: 393.77593485514325, Validation RMSE: 410.7197315891539\nEpoch 19/40, Loss: 0.002127544034738094\nValidation MAE: 391.82933553059894, Validation RMSE: 407.48368129390576\nEpoch 20/40, Loss: 0.0021156845265068113\nValidation MAE: 395.0261942545573, Validation RMSE: 411.54361510709487\nEpoch 21/40, Loss: 0.002118912455625832\nValidation MAE: 394.5326639811198, Validation RMSE: 411.33592852284374\nEpoch 22/40, Loss: 0.002116676897276193\nValidation MAE: 393.584966023763, Validation RMSE: 410.5625\nEpoch 23/40, Loss: 0.002085081650875509\nValidation MAE: 391.61863708496094, Validation RMSE: 408.6485109097426\nEpoch 24/40, Loss: 0.002084127115085721\nValidation MAE: 391.4456481933594, Validation RMSE: 408.1638381214093\nEpoch 25/40, Loss: 0.0021420624339953064\nValidation MAE: 392.7294921875, Validation RMSE: 409.73460509771854\nEpoch 26/40, Loss: 0.0020464144996367394\nValidation MAE: 393.0294138590495, Validation RMSE: 409.89243539464104\nEpoch 27/40, Loss: 0.002117850270587951\nValidation MAE: 393.9740295410156, Validation RMSE: 410.632819560249\nEpoch 28/40, Loss: 0.00206452104030177\nValidation MAE: 394.8159535725911, Validation RMSE: 411.1288607044836\nEpoch 29/40, Loss: 0.002128010243177414\nValidation MAE: 392.65306599934894, Validation RMSE: 408.1828139883117\nEarly stopping at epoch 29\nValidation MAE: 394.18592834472656, Validation RMSE: 410.2116704621327\nFold 1 Results - MAE: 394.18592834472656, RMSE: 410.2116704621327\n--------------------------------\nFOLD 2/5\n--------------------------------\nEpoch 1/40, Loss: 0.0027147708926349877\nValidation MAE: 370.0763651529948, Validation RMSE: 387.529071490127\nEpoch 2/40, Loss: 0.0026126620708964766\nValidation MAE: 364.88190205891925, Validation RMSE: 382.4024095956815\nEpoch 3/40, Loss: 0.002486657630652189\nValidation MAE: 359.24046325683594, Validation RMSE: 376.0058195056073\nEpoch 4/40, Loss: 0.0022886560182087123\nValidation MAE: 354.1147054036458, Validation RMSE: 371.08627492471345\nEpoch 5/40, Loss: 0.002137754869181663\nValidation MAE: 351.25107828776044, Validation RMSE: 368.15254919552933\nEpoch 6/40, Loss: 0.0021653131349012255\nValidation MAE: 349.5912373860677, Validation RMSE: 365.87784348627434\nEpoch 7/40, Loss: 0.002090166602283716\nValidation MAE: 347.1723225911458, Validation RMSE: 363.88115834133725\nEpoch 8/40, Loss: 0.0020453507080674172\nValidation MAE: 347.01527404785156, Validation RMSE: 363.8982712557407\nEpoch 9/40, Loss: 0.002118038071785122\nValidation MAE: 344.7649180094401, Validation RMSE: 361.1630373990856\nEpoch 10/40, Loss: 0.0019900219107512386\nValidation MAE: 341.7689208984375, Validation RMSE: 357.68682836735826\nEpoch 11/40, Loss: 0.001986083947122097\nValidation MAE: 341.20721944173175, Validation RMSE: 357.36388361514656\nEpoch 12/40, Loss: 0.0020412582904100417\nValidation MAE: 343.5505116780599, Validation RMSE: 360.4493632808682\nEpoch 13/40, Loss: 0.002001915534492582\nValidation MAE: 343.32152303059894, Validation RMSE: 360.26250918022726\nEpoch 14/40, Loss: 0.0020404035341925917\nValidation MAE: 342.52687581380206, Validation RMSE: 358.979626714154\nEpoch 15/40, Loss: 0.0020658547058701516\nValidation MAE: 340.30670166015625, Validation RMSE: 356.40953664639784\nEpoch 16/40, Loss: 0.0020201676874421538\nValidation MAE: 340.451904296875, Validation RMSE: 356.68960997565284\nEpoch 17/40, Loss: 0.0020674205617979167\nValidation MAE: 338.46453857421875, Validation RMSE: 355.0080764926342\nEpoch 18/40, Loss: 0.0019442484597675502\nValidation MAE: 336.97223409016925, Validation RMSE: 353.02306050738383\nEpoch 19/40, Loss: 0.0019979240547399967\nValidation MAE: 339.5347900390625, Validation RMSE: 356.29720995668305\nEpoch 20/40, Loss: 0.0020365275675430896\nValidation MAE: 338.8944346110026, Validation RMSE: 355.02069151846626\nEpoch 21/40, Loss: 0.0019448334118351341\nValidation MAE: 340.2437388102214, Validation RMSE: 356.2897620354113\nEpoch 22/40, Loss: 0.001973706006538123\nValidation MAE: 340.4894612630208, Validation RMSE: 356.81423884378086\nEpoch 23/40, Loss: 0.0019983195466920733\nValidation MAE: 339.2225850423177, Validation RMSE: 355.6012239415804\nEarly stopping at epoch 23\nValidation MAE: 340.2657470703125, Validation RMSE: 356.85942756450567\nFold 2 Results - MAE: 340.2657470703125, RMSE: 356.85942756450567\n--------------------------------\nFOLD 3/5\n--------------------------------\nEpoch 1/40, Loss: 0.006208322988823056\nValidation MAE: 387.93450419108075, Validation RMSE: 438.542256655383\nEpoch 2/40, Loss: 0.005399216222576797\nValidation MAE: 398.6775767008464, Validation RMSE: 449.8144770925935\nEpoch 3/40, Loss: 0.004409882659092546\nValidation MAE: 406.0148518880208, Validation RMSE: 458.8174117420876\nEpoch 4/40, Loss: 0.0035396842053160072\nValidation MAE: 417.3576253255208, Validation RMSE: 468.7391651525576\nEpoch 5/40, Loss: 0.003007595834787935\nValidation MAE: 422.7434387207031, Validation RMSE: 474.12061278618756\nEpoch 6/40, Loss: 0.002537878812290728\nValidation MAE: 427.44176228841144, Validation RMSE: 479.5191866762215\nEarly stopping at epoch 6\nValidation MAE: 424.5321350097656, Validation RMSE: 476.661997810031\nFold 3 Results - MAE: 424.5321350097656, RMSE: 476.661997810031\n--------------------------------\nFOLD 4/5\n--------------------------------\nEpoch 1/40, Loss: 0.006460499763488769\nValidation MAE: 369.5037078857422, Validation RMSE: 429.93241618535717\nEpoch 2/40, Loss: 0.005161788873374462\nValidation MAE: 388.75136311848956, Validation RMSE: 444.9209645695982\nEpoch 3/40, Loss: 0.004529294022358954\nValidation MAE: 399.31516520182294, Validation RMSE: 455.865500797887\nEpoch 4/40, Loss: 0.0036383480997756123\nValidation MAE: 414.13307698567706, Validation RMSE: 467.99860401434427\nEpoch 5/40, Loss: 0.003309760882984847\nValidation MAE: 420.61321512858075, Validation RMSE: 472.56974242785935\nEpoch 6/40, Loss: 0.002756177261471748\nValidation MAE: 423.619140625, Validation RMSE: 475.69494393728843\nEarly stopping at epoch 6\nValidation MAE: 424.7722880045573, Validation RMSE: 476.1047487379572\nFold 4 Results - MAE: 424.7722880045573, RMSE: 476.1047487379572\n--------------------------------\nFOLD 5/5\n--------------------------------\nEpoch 1/40, Loss: 0.0024013738613575695\nValidation MAE: 228.81102244059244, Validation RMSE: 262.4175181984272\nEpoch 2/40, Loss: 0.002253876405302435\nValidation MAE: 232.360720316569, Validation RMSE: 265.3225997721826\nEpoch 3/40, Loss: 0.0021432902780361474\nValidation MAE: 237.50474548339844, Validation RMSE: 269.31285536063814\nEpoch 4/40, Loss: 0.0018948704120703042\nValidation MAE: 241.5718739827474, Validation RMSE: 275.617421977505\nEpoch 5/40, Loss: 0.0018311065970920027\nValidation MAE: 241.68154652913412, Validation RMSE: 274.0653267088642\nEpoch 6/40, Loss: 0.0018302245414815843\nValidation MAE: 243.39164861043295, Validation RMSE: 276.02482058462795\nEarly stopping at epoch 6\nValidation MAE: 245.10210418701172, Validation RMSE: 278.10464637603144\nFold 5 Results - MAE: 245.10210418701172, RMSE: 278.10464637603144\n--------------------------------\n\nCross-validation Results:\nAverage MAE: 365.77164052327475\nAverage RMSE: 399.5884981901316\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}